model:
  internvl_path: /home/jiachun/ckpt/OpenGVLab/InternVL3_5-1B
  embedding_dim: 256
  llm_hidden_size: 1024

  quantizer:
    ckpt_path: null
    vq_type: multi_vq # [vq, lfq, multi_vq]
    type: MLP # [MLP, ViT]
    input_feature_dim: 4096
    embedding_dim: 256
    llm_hidden_size: 2560
    num_embeddings: 2048
    num_codebooks: 8

  ar_head:
    num_codebooks: 8
    num_embeddings: 2048
    hidden_size: 1024

train:
  root: /home/jiachun/experiment
  resume_path: null
  skip_keys: []
  global_step: 0

  exp_name: &exp_name dev
  proj_name: *exp_name
  output_dir: 1205_dev_ar_head
  logging_dir: logs
  mixed_precision: bf16
  gradient_accumulation_steps: 1
  report_to: null

  lr: 1e-4
  num_iter: 1000000
  save_every: 5000

data:
  wds_path: [/home/jiachun/dataset/BLIP3o/BLIP3o-Pretrain-Short-Caption]
  img_size: 448
  cfg_drop_rate: 0.0
  num_img_token: 256
  max_seq_length: 512
  buffer_size: 5
  batch_size: 2
  num_workers: 8